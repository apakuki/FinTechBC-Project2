{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customer Churn Prediction\n",
    "\n",
    "Customer churn or customer attrition is a tendency of clients or customers to abandon a brand and stop being paying clients of a particular business or organization. The percentage of customers discontinuing using a company’s services or products during a specific period is called a customer churn rate. Several bad experiences (or just one) are enough, and a customer may quit. And if a large chunk of unsatisfied customers churn at a time interval, both material losses and damage to reputation would be enormous.\n",
    "\n",
    "Using machine learning techniques, financial services companies use their customer data to identify behavior patterns of potential churners, classify these at-risk customers, and take appropriate actions to gain their trust and increase their retention rate. The task is to classify customers as churners or non-churners (binary classification) based on the organization’s historical data sources.\n",
    "\n",
    "To perform the classification task, you can use machine learning classification algorithms like Logistic regression, Naive Bayes Classifier, Tree-based algorithms, Random Forest, etc. To increase efficiency, you can use advanced algorithms like XGBoost, LightGBM, or CatBoost. Use the accuracy metrics to compare the performance of the different models. You can use the Bank Customers Dataset for Churn to practice this project.\n",
    "\n",
    "#### Train and Evaluate the Neural Network Model\n",
    "\n",
    "1. Train (fit) the neural network model. Use the training data and set 100 epochs.\n",
    "\n",
    "2. Evaluate the model using the test data to determine its loss and accuracy.\n",
    "\n",
    "\n",
    "## References:\n",
    "\n",
    "[Keras Sequential model](https://keras.io/api/models/sequential/)\n",
    "\n",
    "[Keras Dense module](https://keras.io/api/layers/core_layers/dense/)\n",
    "\n",
    "[Keras evaluate](https://keras.io/api/models/model_training_apis/)\n",
    "\n",
    "[SKLearn OneHotEncoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Preprocess the data.\n",
    "### Step 1: Read the `Churn_Modelling.csv` file from the Resources folder and create a DataFrame.\n",
    "# Read the HR-Employee-Attrition.csv file from the Resources folder into a Pandas DataFrame\n",
    "customer_df = pd.read_csv(Path(\"Churn_Modelling.csv\"))\n",
    "customer_df\n",
    "### Step 2: Review the resulting DataFrame. Check the data type associated with each column to identify categorical and non-categorical variables.\n",
    "\n",
    "> **Hint** Recall that categorical variables have an `object` data type.\n",
    "\n",
    "# Review the DataFrame\n",
    "display(customer_df.head())\n",
    "\n",
    "# Review the data types associated with the columns\n",
    "display(customer_df.dtypes)\n",
    "display(customer_df.shape)\n",
    "### Step 3: Create a list of categorical variables.\n",
    "# Create a list of categorical variables \n",
    "categorical_variables = list(customer_df.dtypes[customer_df.dtypes == \"object\"].index)\n",
    "categorical_variables = \n",
    "# Create a OneHotEncoder instance\n",
    "enc = OneHotEncoder(sparse=False)\n",
    "\n",
    "# Encode categorcal variables using OneHotEncoder\n",
    "encoded_data = enc.fit_transform(customer_df[categorical_variables])\n",
    "\n",
    "# Create a DataFrame with the encoded variables\n",
    "# The column names should match those of the encoded variables\n",
    "encoded_df = pd.DataFrame(encoded_data,columns = enc.get_feature_names_out(categorical_variables))\n",
    "encoded_df\n",
    "# Create a DataFrame with the columnns containing numerical variables from the original dataset\n",
    "numerical_variables_df = encoded_df.drop(columns = categorical_variables)\n",
    "\n",
    "# Using the Pandas concat function, combine the DataFrames the contain the encoded categorical data and the numerical data\n",
    "attition_df = pd.concat([numerical_variables_df,encoded_df],axis=1)\n",
    "\n",
    "# Reveiw the DataFrame\n",
    "attition_df.head()\n",
    "# Define the target set y using the Attrition_Yes column\n",
    "y = attition_df[\"Attrition_Yes\"]\n",
    "\n",
    "\n",
    "# Define features set X by selecting all columns but Attrition_Yes and Attrition_No\n",
    "X = attition_df.drop(columns=[\"Attrition_Yes\", \"Attrition_No\"])\n",
    "\n",
    "# Review the features DataFrameb\n",
    "display(y.shape)\n",
    "display(X.shape)\n",
    "### Step 7: Create the training and testing sets using the `train_test_split` function from scikit-learn.\n",
    "# Split the data into training and testing datasets\n",
    "# Assign the function a random_state equal to 1\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, stratify=y)\n",
    "\n",
    "# Create a StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler to the features training dataset\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Fit the scaler to the features training dataset\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "---\n",
    "\n",
    "## Create a Neural Network Model to Predict Employee Attrition\n",
    "### Step 1: Use the optimization techniques presented in this lesson to create a deep neural network model with two hidden layers.\n",
    "# Define the the number of inputs (features) to the model (i.e. 55 = columns of X)\n",
    "number_input_features = len(X_train.iloc[0])\n",
    "\n",
    "# Define the number of hidden nodes for the first hidden layer\n",
    "# Use the mean of the number of input features plus the number of output nurons\n",
    "# Use the Python floor division (//) to return the quotent\n",
    "hidden_nodes_layer1 =  (number_input_features + 1) // 2 \n",
    "\n",
    "# Define the number of hidden nodes for the second hidden layer\n",
    "# Use the mean of the number of hidden nodes in the first hidden layer plus the number of output nurons\n",
    "# Use the Python floor division (//) to return the quotent\n",
    "hidden_nodes_layer2 = (hidden_nodes_layer1 + 1) // 2\n",
    "\n",
    "# Create the Sequential model instance\n",
    "nn = Sequential()\n",
    "\n",
    "# Add the first hidden layer specifying the number of inputs, the number of hidden nodes, and the activation function\n",
    "nn.add(Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\"))\n",
    "\n",
    "# Add the second hidden layer specifying the number of hidden nodes and the activation function\n",
    "nn.add(Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "\n",
    "# Add the output layer to the model specifying the number of output neurons and activation function\n",
    "# This model will predict a binary output. So, add an output layer with one neuron, and use the `sigmoid` activation function.\n",
    "nn.add(Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Display the Sequential model summary\n",
    "nn.summary()\n",
    "### Step 2: Compile the model. Use the `binary_crossentropy` loss function, the `adam` optimizer, and the `accuracy` metric.\n",
    "# Compile the Sequential model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "### Step 3: Train (fit) the neural network model. Use the training data and set 100 epochs.\n",
    "\n",
    "# Fit the model using 100 epochs and the training data\n",
    "fit_model = nn.fit(X_train_scaled, y_train, epochs=100)\n",
    "### Step 4: Evaluate the model using the test data to determine its loss and accuracy.\n",
    "# Evaluate the model loss and accuracy metrics using the evaluate method and the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "\n",
    "# Display the model loss and accuracy results\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.15 (default, Nov  9 2022, 10:44:37) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "450033cf19dd54ad3d30c8e8281e886ebd40313abd5cee9d0398a27fcccc0e94"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
