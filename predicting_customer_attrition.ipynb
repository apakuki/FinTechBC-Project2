{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customer Churn Prediction\n",
    "\n",
    "Customer churn or customer attrition is a tendency of clients or customers to abandon a brand and stop being paying clients of a particular business or organization. The percentage of customers discontinuing using a company’s services or products during a specific period is called a customer churn rate. Several bad experiences (or just one) are enough, and a customer may quit. And if a large chunk of unsatisfied customers churn at a time interval, both material losses and damage to reputation would be enormous.\n",
    "\n",
    "Using machine learning techniques, financial services companies use their customer data to identify behavior patterns of potential churners, classify these at-risk customers, and take appropriate actions to gain their trust and increase their retention rate. The task is to classify customers as churners or non-churners (binary classification) based on the organization’s historical data sources.\n",
    "\n",
    "To perform the classification task, you can use machine learning classification algorithms like Logistic regression, Naive Bayes Classifier, Tree-based algorithms, Random Forest, etc. To increase efficiency, you can use advanced algorithms like XGBoost, LightGBM, or CatBoost. Use the accuracy metrics to compare the performance of the different models. You can use the Bank Customers Dataset for Churn to practice this project.\n",
    "\n",
    "https://www.projectpro.io/article/projects-on-machine-learning-applications-in-finance/510#mcetoc_1gla0jmc415\n",
    "\n",
    "#### Train and Evaluate the Neural Network Model\n",
    "\n",
    "1. Train (fit) the neural network model. Use the training data and set 100 epochs.\n",
    "\n",
    "2. Evaluate the model using the test data to determine its loss and accuracy.\n",
    "\n",
    "\n",
    "## References:\n",
    "\n",
    "[Keras Sequential model](https://keras.io/api/models/sequential/)\n",
    "\n",
    "[Keras Dense module](https://keras.io/api/layers/core_layers/dense/)\n",
    "\n",
    "[Keras evaluate](https://keras.io/api/models/model_training_apis/)\n",
    "\n",
    "[SKLearn OneHotEncoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Preprocess the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Read the `Churn_Modelling.csv` file from the Resources folder and create a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>9996</td>\n",
       "      <td>15606229</td>\n",
       "      <td>Obijiaku</td>\n",
       "      <td>771</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>9997</td>\n",
       "      <td>15569892</td>\n",
       "      <td>Johnstone</td>\n",
       "      <td>516</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>9998</td>\n",
       "      <td>15584532</td>\n",
       "      <td>Liu</td>\n",
       "      <td>709</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9999</td>\n",
       "      <td>15682355</td>\n",
       "      <td>Sabbatini</td>\n",
       "      <td>772</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>10000</td>\n",
       "      <td>15628319</td>\n",
       "      <td>Walker</td>\n",
       "      <td>792</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      RowNumber  CustomerId    Surname  CreditScore Geography  Gender  Age  \\\n",
       "0             1    15634602   Hargrave          619    France  Female   42   \n",
       "1             2    15647311       Hill          608     Spain  Female   41   \n",
       "2             3    15619304       Onio          502    France  Female   42   \n",
       "3             4    15701354       Boni          699    France  Female   39   \n",
       "4             5    15737888   Mitchell          850     Spain  Female   43   \n",
       "...         ...         ...        ...          ...       ...     ...  ...   \n",
       "9995       9996    15606229   Obijiaku          771    France    Male   39   \n",
       "9996       9997    15569892  Johnstone          516    France    Male   35   \n",
       "9997       9998    15584532        Liu          709    France  Female   36   \n",
       "9998       9999    15682355  Sabbatini          772   Germany    Male   42   \n",
       "9999      10000    15628319     Walker          792    France  Female   28   \n",
       "\n",
       "      Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0          2       0.00              1          1               1   \n",
       "1          1   83807.86              1          0               1   \n",
       "2          8  159660.80              3          1               0   \n",
       "3          1       0.00              2          0               0   \n",
       "4          2  125510.82              1          1               1   \n",
       "...      ...        ...            ...        ...             ...   \n",
       "9995       5       0.00              2          1               0   \n",
       "9996      10   57369.61              1          1               1   \n",
       "9997       7       0.00              1          0               1   \n",
       "9998       3   75075.31              2          1               0   \n",
       "9999       4  130142.79              1          1               0   \n",
       "\n",
       "      EstimatedSalary  Exited  \n",
       "0           101348.88       1  \n",
       "1           112542.58       0  \n",
       "2           113931.57       1  \n",
       "3            93826.63       0  \n",
       "4            79084.10       0  \n",
       "...               ...     ...  \n",
       "9995         96270.64       0  \n",
       "9996        101699.77       0  \n",
       "9997         42085.58       1  \n",
       "9998         92888.52       1  \n",
       "9999         38190.78       0  \n",
       "\n",
       "[10000 rows x 14 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the HR-Employee-Attrition.csv file from the Resources folder into a Pandas DataFrame\n",
    "customer_df = pd.read_csv(Path(\"./Resources/Churn_Modelling.csv\"))\n",
    "customer_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RowNumber          0\n",
       "CustomerId         0\n",
       "Surname            0\n",
       "CreditScore        0\n",
       "Geography          0\n",
       "Gender             0\n",
       "Age                0\n",
       "Tenure             0\n",
       "Balance            0\n",
       "NumOfProducts      0\n",
       "HasCrCard          0\n",
       "IsActiveMember     0\n",
       "EstimatedSalary    0\n",
       "Exited             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data cleaninng: checking number of null\n",
    "customer_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Review the resulting DataFrame. Check the data type associated with each column to identify categorical and non-categorical variables.\n",
    "\n",
    "> **Hint** Recall that categorical variables have an `object` data type.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "RowNumber            int64\n",
       "CustomerId           int64\n",
       "Surname             object\n",
       "CreditScore          int64\n",
       "Geography           object\n",
       "Gender              object\n",
       "Age                  int64\n",
       "Tenure               int64\n",
       "Balance            float64\n",
       "NumOfProducts        int64\n",
       "HasCrCard            int64\n",
       "IsActiveMember       int64\n",
       "EstimatedSalary    float64\n",
       "Exited               int64\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(10000, 14)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Review the DataFrame\n",
    "display(customer_df.head())\n",
    "\n",
    "# Review the data types associated with the columns\n",
    "display(customer_df.dtypes)\n",
    "display(customer_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Create a list of categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of categorical variables \n",
    "categorical_variables = list(customer_df.dtypes[customer_df.dtypes == \"object\"].index)\n",
    "categorical_variables = ['Geography', 'Gender']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Geography_France</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>Gender_Female</th>\n",
       "      <th>Gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Geography_France  Geography_Germany  Geography_Spain  Gender_Female  \\\n",
       "0                  1.0                0.0              0.0            1.0   \n",
       "1                  0.0                0.0              1.0            1.0   \n",
       "2                  1.0                0.0              0.0            1.0   \n",
       "3                  1.0                0.0              0.0            1.0   \n",
       "4                  0.0                0.0              1.0            1.0   \n",
       "...                ...                ...              ...            ...   \n",
       "9995               1.0                0.0              0.0            0.0   \n",
       "9996               1.0                0.0              0.0            0.0   \n",
       "9997               1.0                0.0              0.0            1.0   \n",
       "9998               0.0                1.0              0.0            0.0   \n",
       "9999               1.0                0.0              0.0            1.0   \n",
       "\n",
       "      Gender_Male  \n",
       "0             0.0  \n",
       "1             0.0  \n",
       "2             0.0  \n",
       "3             0.0  \n",
       "4             0.0  \n",
       "...           ...  \n",
       "9995          1.0  \n",
       "9996          1.0  \n",
       "9997          0.0  \n",
       "9998          1.0  \n",
       "9999          0.0  \n",
       "\n",
       "[10000 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a OneHotEncoder instance\n",
    "enc = OneHotEncoder(sparse=False)\n",
    "\n",
    "# Encode categorcal variables using OneHotEncoder\n",
    "encoded_data = enc.fit_transform(customer_df[categorical_variables])\n",
    "\n",
    "# Create a DataFrame with the encoded variables\n",
    "# The column names should match those of the encoded variables\n",
    "encoded_df = pd.DataFrame(encoded_data,columns = enc.get_feature_names_out(categorical_variables))\n",
    "encoded_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Geography_France', 'Geography_Germany', 'Geography_Spain',\n",
       "       'Gender_Female', 'Gender_Male'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_variables = encoded_df.columns\n",
    "categorical_variables\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Geography_France</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>Gender_Female</th>\n",
       "      <th>Gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>619</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>608</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>502</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>699</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>850</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId  CreditScore  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0          1    15634602          619   42       2       0.00              1   \n",
       "1          2    15647311          608   41       1   83807.86              1   \n",
       "2          3    15619304          502   42       8  159660.80              3   \n",
       "3          4    15701354          699   39       1       0.00              2   \n",
       "4          5    15737888          850   43       2  125510.82              1   \n",
       "\n",
       "   HasCrCard  IsActiveMember  EstimatedSalary  Exited  Geography_France  \\\n",
       "0          1               1        101348.88       1               1.0   \n",
       "1          0               1        112542.58       0               0.0   \n",
       "2          1               0        113931.57       1               1.0   \n",
       "3          0               0         93826.63       0               1.0   \n",
       "4          1               1         79084.10       0               0.0   \n",
       "\n",
       "   Geography_Germany  Geography_Spain  Gender_Female  Gender_Male  \n",
       "0                0.0              0.0            1.0          0.0  \n",
       "1                0.0              1.0            1.0          0.0  \n",
       "2                0.0              0.0            1.0          0.0  \n",
       "3                0.0              0.0            1.0          0.0  \n",
       "4                0.0              1.0            1.0          0.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a DataFrame with the columnns containing numerical variables from the original dataset\n",
    "numerical_variables_df = customer_df.drop(columns = ['Surname','Geography', 'Gender'])\n",
    "\n",
    "# Using the Pandas concat function, combine the DataFrames the contain the encoded categorical data and the numerical data\n",
    "attrition_df = pd.concat([numerical_variables_df,encoded_df],axis=1)\n",
    "\n",
    "# Reveiw the DataFrame\n",
    "attrition_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(10000, 15)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the target set y using the Attrition_Yes column\n",
    "y = attrition_df[\"Exited\"]\n",
    "\n",
    "\n",
    "# Define features set X by selecting all columns but Attrition_Yes and Attrition_No\n",
    "X = attrition_df.drop(columns=[\"Exited\"])\n",
    "\n",
    "# Review the features DataFrameb\n",
    "display(y.shape)\n",
    "display(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Create the training and testing sets using the `train_test_split` function from scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 15)\n",
      "(8000,)\n",
      "(1000, 15)\n",
      "(1000,)\n",
      "(1000, 15)\n",
      "(1000,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the data into training and testing datasets\n",
    "# We can use the train_test_split to first make the split on the original dataset. \n",
    "# Then, to get the validation set, we can apply the same function to the train set to get the validation set.\n",
    "\n",
    "# https://towardsdatascience.com/how-to-split-data-into-three-sets-train-validation-and-test-and-why-e50d22d3e54c\n",
    "\n",
    "# Let's say we want to split the data in 80:10:10 for train:valid:test dataset\n",
    "train_size=0.8\n",
    "\n",
    "# In the first step we will split the data in training and remaining dataset\n",
    "X_train, X_rem, y_train, y_rem = train_test_split(X,y, train_size=0.8)\n",
    "\n",
    "# Now since we want the valid and test size to be equal (10% each of overall data). \n",
    "# we have to define valid_size=0.5 (that is 50% of remaining data)\n",
    "test_size = 0.5\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_rem,y_rem, test_size=0.5)\n",
    "\n",
    "print(X_train.shape), print(y_train.shape)\n",
    "print(X_valid.shape), print(y_valid.shape)\n",
    "print(X_test.shape), print(y_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler to the features training dataset\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Fit the scaler to the features training dataset\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_valid_scaled = X_scaler.transform(X_valid)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Create a Neural Network Model to Predict Employee Attrition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Use the optimization techniques presented in this lesson to create a deep neural network model with two hidden layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 8)                 128       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4)                 36        \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 5         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 169\n",
      "Trainable params: 169\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the the number of inputs (features) to the model (i.e. 55 = columns of X)\n",
    "number_input_features = len(X_train.iloc[0])\n",
    "\n",
    "# Define the number of hidden nodes for the first hidden layer\n",
    "# Use the mean of the number of input features plus the number of output nurons\n",
    "# Use the Python floor division (//) to return the quotent\n",
    "hidden_nodes_layer1 =  (number_input_features + 1) // 2 \n",
    "\n",
    "# Define the number of hidden nodes for the second hidden layer\n",
    "# Use the mean of the number of hidden nodes in the first hidden layer plus the number of output nurons\n",
    "# Use the Python floor division (//) to return the quotent\n",
    "hidden_nodes_layer2 = (hidden_nodes_layer1 + 1) // 2\n",
    "\n",
    "# Create the Sequential model instance\n",
    "nn = Sequential()\n",
    "\n",
    "# Add the first hidden layer specifying the number of inputs, the number of hidden nodes, and the activation function\n",
    "nn.add(Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\"))\n",
    "\n",
    "# Add the second hidden layer specifying the number of hidden nodes and the activation function\n",
    "nn.add(Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "\n",
    "# Add the output layer to the model specifying the number of output neurons and activation function\n",
    "# This model will predict a binary output. So, add an output layer with one neuron, and use the `sigmoid` activation function.\n",
    "nn.add(Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Display the Sequential model summary\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Compile the model. Use the `binary_crossentropy` loss function, the `adam` optimizer, and the `accuracy` metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the Sequential model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Train (fit) the neural network model. Use the training data and set 100 epochs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "235/235 [==============================] - 1s 1ms/step - loss: 0.5383 - accuracy: 0.7959\n",
      "Epoch 2/100\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4670 - accuracy: 0.7963\n",
      "Epoch 3/100\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4430 - accuracy: 0.7963\n",
      "Epoch 4/100\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4320 - accuracy: 0.7961\n",
      "Epoch 5/100\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4265 - accuracy: 0.7964\n",
      "Epoch 6/100\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.4226 - accuracy: 0.7967\n",
      "Epoch 7/100\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.4193 - accuracy: 0.8052\n",
      "Epoch 8/100\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.4167 - accuracy: 0.8172\n",
      "Epoch 9/100\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.4139 - accuracy: 0.8196\n",
      "Epoch 10/100\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.4110 - accuracy: 0.8235\n",
      "Epoch 11/100\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.4077 - accuracy: 0.8267\n",
      "Epoch 12/100\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.4033 - accuracy: 0.8303\n",
      "Epoch 13/100\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.3959 - accuracy: 0.8357\n",
      "Epoch 14/100\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.3852 - accuracy: 0.8423\n",
      "Epoch 15/100\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.3750 - accuracy: 0.8451\n",
      "Epoch 16/100\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.3660 - accuracy: 0.8501\n",
      "Epoch 17/100\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3599 - accuracy: 0.8529\n",
      "Epoch 18/100\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.3551 - accuracy: 0.8547\n",
      "Epoch 19/100\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3516 - accuracy: 0.8588\n",
      "Epoch 20/100\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3490 - accuracy: 0.8603\n",
      "Epoch 21/100\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3470 - accuracy: 0.8607\n",
      "Epoch 22/100\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3441 - accuracy: 0.8605\n",
      "Epoch 23/100\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3445 - accuracy: 0.8620\n",
      "Epoch 24/100\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3425 - accuracy: 0.8623\n",
      "Epoch 25/100\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3416 - accuracy: 0.8629\n",
      "Epoch 26/100\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3405 - accuracy: 0.8641\n",
      "Epoch 27/100\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3398 - accuracy: 0.8648\n",
      "Epoch 28/100\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3383 - accuracy: 0.8627\n",
      "Epoch 29/100\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3361 - accuracy: 0.8633\n",
      "Epoch 30/100\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3344 - accuracy: 0.8620\n",
      "Epoch 31/100\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3333 - accuracy: 0.8645\n",
      "Epoch 32/100\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3324 - accuracy: 0.8661\n",
      "Epoch 33/100\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3314 - accuracy: 0.8631\n",
      "Epoch 34/100\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3314 - accuracy: 0.8653\n",
      "Epoch 35/100\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3307 - accuracy: 0.8657\n",
      "Epoch 36/100\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3303 - accuracy: 0.8639\n",
      "Epoch 37/100\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3300 - accuracy: 0.8649\n",
      "Epoch 38/100\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.3299 - accuracy: 0.8629\n",
      "Epoch 39/100\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.3299 - accuracy: 0.8644\n",
      "Epoch 40/100\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3296 - accuracy: 0.8651\n",
      "Epoch 41/100\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.3293 - accuracy: 0.8627\n",
      "Epoch 42/100\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3294 - accuracy: 0.8647\n",
      "Epoch 43/100\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3292 - accuracy: 0.8647\n",
      "Epoch 44/100\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3292 - accuracy: 0.8629\n",
      "Epoch 45/100\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3285 - accuracy: 0.8648\n",
      "Epoch 46/100\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3285 - accuracy: 0.8628\n",
      "Epoch 47/100\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3287 - accuracy: 0.8659\n",
      "Epoch 48/100\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3282 - accuracy: 0.8637\n",
      "Epoch 49/100\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3282 - accuracy: 0.8643\n",
      "Epoch 50/100\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3277 - accuracy: 0.8655\n",
      "Epoch 51/100\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3278 - accuracy: 0.8643\n",
      "Epoch 52/100\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3277 - accuracy: 0.8648\n",
      "Epoch 53/100\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3273 - accuracy: 0.8652\n",
      "Epoch 54/100\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3271 - accuracy: 0.8665\n",
      "Epoch 55/100\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3269 - accuracy: 0.8664\n",
      "Epoch 56/100\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3267 - accuracy: 0.8660\n",
      "Epoch 57/100\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3266 - accuracy: 0.8663\n",
      "Epoch 58/100\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.3264 - accuracy: 0.8655\n",
      "Epoch 59/100\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3263 - accuracy: 0.8668\n",
      "Epoch 60/100\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3262 - accuracy: 0.8671\n",
      "Epoch 61/100\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3254 - accuracy: 0.8675\n",
      "Epoch 62/100\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3259 - accuracy: 0.8649\n",
      "Epoch 63/100\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3255 - accuracy: 0.8663\n",
      "Epoch 64/100\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3255 - accuracy: 0.8665\n",
      "Epoch 65/100\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3255 - accuracy: 0.8649\n",
      "Epoch 66/100\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3249 - accuracy: 0.8643\n",
      "Epoch 67/100\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3252 - accuracy: 0.8663\n",
      "Epoch 68/100\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3250 - accuracy: 0.8675\n",
      "Epoch 69/100\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3247 - accuracy: 0.8669\n",
      "Epoch 70/100\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3247 - accuracy: 0.8671\n",
      "Epoch 71/100\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3246 - accuracy: 0.8659\n",
      "Epoch 72/100\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3246 - accuracy: 0.8668\n",
      "Epoch 73/100\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3246 - accuracy: 0.8668\n",
      "Epoch 74/100\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3242 - accuracy: 0.8655\n",
      "Epoch 75/100\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3241 - accuracy: 0.8663\n",
      "Epoch 76/100\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3245 - accuracy: 0.8667\n",
      "Epoch 77/100\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3244 - accuracy: 0.8664\n",
      "Epoch 78/100\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3244 - accuracy: 0.8676\n",
      "Epoch 79/100\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.3241 - accuracy: 0.8672\n",
      "Epoch 80/100\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3239 - accuracy: 0.8663\n",
      "Epoch 81/100\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3239 - accuracy: 0.8656\n",
      "Epoch 82/100\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3237 - accuracy: 0.8669\n",
      "Epoch 83/100\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.3237 - accuracy: 0.8664\n",
      "Epoch 84/100\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.3237 - accuracy: 0.8672\n",
      "Epoch 85/100\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.3233 - accuracy: 0.8681\n",
      "Epoch 86/100\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3236 - accuracy: 0.8675\n",
      "Epoch 87/100\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.3239 - accuracy: 0.8657\n",
      "Epoch 88/100\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.3234 - accuracy: 0.8653\n",
      "Epoch 89/100\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.3233 - accuracy: 0.8671\n",
      "Epoch 90/100\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.3229 - accuracy: 0.8679\n",
      "Epoch 91/100\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3231 - accuracy: 0.8671\n",
      "Epoch 92/100\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.3229 - accuracy: 0.8681\n",
      "Epoch 93/100\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.3231 - accuracy: 0.8667\n",
      "Epoch 94/100\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.3230 - accuracy: 0.8675\n",
      "Epoch 95/100\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.3227 - accuracy: 0.8672\n",
      "Epoch 96/100\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.3230 - accuracy: 0.8669\n",
      "Epoch 97/100\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.3229 - accuracy: 0.8680\n",
      "Epoch 98/100\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3223 - accuracy: 0.8681\n",
      "Epoch 99/100\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3217 - accuracy: 0.8671\n",
      "Epoch 100/100\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3221 - accuracy: 0.8679\n"
     ]
    }
   ],
   "source": [
    "# Fit the model using 100 epochs and the training data\n",
    "fit_model = nn.fit(X_train_scaled, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Evaluate the model using the test data to determine its loss and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 - 0s - loss: 0.3568 - accuracy: 0.8604 - 225ms/epoch - 3ms/step\n",
      "Loss: 0.356794536113739, Accuracy: 0.8604000210762024\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model loss and accuracy metrics using the evaluate method and the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "\n",
    "# Display the model loss and accuracy results\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling using Logistic Regression with the Original Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Step 1: Fit a logistic regression model by using the training data (`X_train` and `y_train`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import the LogisticRegression module from SKLearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Instantiate the Logistic Regression model\n",
    "# Assign a random_state parameter of 1 to the model\n",
    "# YOUR CODE HERE!\n",
    "classifier = LogisticRegression(solver='lbfgs', random_state=1)\n",
    "classifier\n",
    "# Fit the model using training data\n",
    "# YOUR CODE HERE!\n",
    "classifier.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Save the predictions on the testing data labels by using the testing feature data (`X_test`) and the fitted model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a prediction using the testing data\n",
    "# YOUR CODE HERE!\n",
    "predictions = classifier.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Evaluate the model’s performance by doing the following:\n",
    "\n",
    "* Calculate the accuracy score of the model.\n",
    "\n",
    "* Generate a confusion matrix.\n",
    "\n",
    "* Print the classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.59502327689202"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the balanced_accuracy score of the model\n",
    "# YOUR CODE HERE!\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "# Display the accuracy score for the test dataset.\n",
    "balanced_accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[755,  28],\n",
       "       [168,  49]], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate a confusion matrix for the model\n",
    "# YOUR CODE HERE!\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Exited-0       0.82      0.96      0.89       783\n",
      "    Stayed-1       0.64      0.23      0.33       217\n",
      "\n",
      "    accuracy                           0.80      1000\n",
      "   macro avg       0.73      0.60      0.61      1000\n",
      "weighted avg       0.78      0.80      0.77      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the classification report for the model\n",
    "# YOUR CODE HERE!\n",
    "from sklearn.metrics import classification_report\n",
    "target_names = [\"Exited-0\", \"Stayed-1\"]\n",
    "print(classification_report(y_test, predictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict a Logistic Regression Model with Resampled Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Use the `RandomOverSampler` module from the imbalanced-learn library to resample the data. Be sure to confirm that the labels have an equal number of data points. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the RandomOverSampler module form imbalanced-learn\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# Instantiate the random oversampler model\n",
    "# # Assign a random_state parameter of 1 to the model\n",
    "# YOUR CODE HERE!\n",
    "random_oversampler = RandomOverSampler(random_state=1)\n",
    "\n",
    "# Fit the original training data to the random_oversampler model\n",
    "# YOUR CODE HERE!\n",
    "X_resampled, y_resampled = random_oversampler.fit_resample(X_train_scaled, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    6367\n",
       "1    6367\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Count the distinct values of the resampled labels data\n",
    "# YOUR CODE HERE!\n",
    "y_resampled.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Use the `LogisticRegression` classifier and the resampled data to fit the model and make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the Logistic Regression model\n",
    "# Assign a random_state parameter of 1 to the model\n",
    "# YOUR CODE HERE!\n",
    "resampled_classifier = LogisticRegression( random_state=1)\n",
    "resampled_classifier\n",
    "# Fit the model using the resampled training data\n",
    "# YOUR CODE HERE!\n",
    "resampled_classifier.fit(X_resampled, y_resampled)\n",
    "# Make a prediction using the testing data\n",
    "# YOUR CODE HERE!\n",
    "resampled_predictions = resampled_classifier.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Evaluate the model’s performance by doing the following:\n",
    "\n",
    "* Calculate the accuracy score of the model.\n",
    "\n",
    "* Generate a confusion matrix.\n",
    "\n",
    "* Print the classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.711799118361966"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the balanced_accuracy score of the model \n",
    "# YOUR CODE HERE!\n",
    "balanced_accuracy_score(y_test, resampled_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[559, 224],\n",
       "       [ 63, 154]], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate a confusion matrix for the model\n",
    "# YOUR CODE HERE!\n",
    "confusion_matrix(y_test, resampled_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "   Exited-0       0.90      0.71      0.71      0.80      0.71      0.51       783\n",
      "   Stayed-1       0.41      0.71      0.71      0.52      0.71      0.51       217\n",
      "\n",
      "avg / total       0.79      0.71      0.71      0.74      0.71      0.51      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the classification report for the model\n",
    "# YOUR CODE HERE!\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "\n",
    "target_names = [\"Exited-0\", \"Stayed-1\"]\n",
    "print(classification_report_imbalanced(y_test, resampled_predictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling using Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a random forest classifier\n",
    "rf_model = RandomForestClassifier(n_estimators=500, random_state=78)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the model\n",
    "rf_model = rf_model.fit(X_train_scaled, y_train)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making Predictions Using the Decsion Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions using the testing data\n",
    "predictions = rf_model.predict(X_test_scaled)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the confusion matrix\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "cm_df = pd.DataFrame(\n",
    "    cm, index=[\"Actual 0\", \"Actual 1\"], columns=[\"Predicted 0\", \"Predicted 1\"]\n",
    ")\n",
    "\n",
    "# Calculating the accuracy score\n",
    "acc_score = accuracy_score(y_test, predictions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted 0</th>\n",
       "      <th>Predicted 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual 0</th>\n",
       "      <td>758</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual 1</th>\n",
       "      <td>128</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Predicted 0  Predicted 1\n",
       "Actual 0          758           25\n",
       "Actual 1          128           89"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.847\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Exited-0       0.86      0.97      0.91       783\n",
      "    Stayed-1       0.78      0.41      0.54       217\n",
      "\n",
      "    accuracy                           0.85      1000\n",
      "   macro avg       0.82      0.69      0.72      1000\n",
      "weighted avg       0.84      0.85      0.83      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Displaying results\n",
    "print(\"Confusion Matrix\")\n",
    "display(cm_df)\n",
    "print(f\"Accuracy Score : {acc_score}\")\n",
    "print(\"Classification Report\")\n",
    "target_names = [\"Exited-0\", \"Stayed-1\"]\n",
    "print(classification_report(y_test, predictions, target_names=target_names))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forests in sklearn will automatically calculate feature importance\n",
    "importances = rf_model.feature_importances_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.20490101667565316, 'Age'),\n",
       " (0.1186610360552868, 'NumOfProducts'),\n",
       " (0.10499725815923944, 'Balance'),\n",
       " (0.10098306344264969, 'EstimatedSalary'),\n",
       " (0.10028852853784988, 'CustomerId'),\n",
       " (0.100143825403658, 'CreditScore'),\n",
       " (0.09913368126434659, 'RowNumber'),\n",
       " (0.05999950210564481, 'Tenure'),\n",
       " (0.03966840855940236, 'IsActiveMember'),\n",
       " (0.021179640239053377, 'Geography_Germany'),\n",
       " (0.014946724436429703, 'HasCrCard'),\n",
       " (0.009782349014218445, 'Geography_France'),\n",
       " (0.008638956174708678, 'Geography_Spain'),\n",
       " (0.008504718776518073, 'Gender_Female'),\n",
       " (0.008171291155340965, 'Gender_Male')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We can sort the features by their importance\n",
    "sorted(zip(rf_model.feature_importances_, X.columns), reverse=True)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling using K-Nearest Neighbors   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Instantiate the model with k = 3 neighbors\n",
    "model = KNeighborsClassifier(n_neighbors=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=3)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "       0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create predictions\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Review the predictions\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[732, 144],\n",
       "       [ 51,  73]], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print confusion matrix\n",
    "confusion_matrix(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Exited-0       0.93      0.84      0.88       876\n",
      "    Stayed-1       0.34      0.59      0.43       124\n",
      "\n",
      "    accuracy                           0.81      1000\n",
      "   macro avg       0.64      0.71      0.66      1000\n",
      "weighted avg       0.86      0.81      0.83      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print classification report\n",
    "print(classification_report(y_pred,y_test, target_names=target_names))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "450033cf19dd54ad3d30c8e8281e886ebd40313abd5cee9d0398a27fcccc0e94"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
